{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W: Final Project**\n",
        "# Graph WaveNet for Deep Spatial-Temporal Graph Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "Spatial-temporal graph modeling is a technique used to analyze and understand complex systems, particularly those with varying behaviors across both spatial (how different components or nodes are related in space) and temporal (how these relationships change over time) dimensions. With the advent of graph neural networks, spatial-temporal graph modeling has received increased attention due to its applicability in diverse problem spaces, encompassing areas like traffic speed forecasting, taxi demand prediction, human action recognition, and more.\n",
        "\n",
        "However, capturing spatial and temporal dependencies simultaneously can be challenging. Recent research has explored integrating graph convolution networks (GCN) into either a recurrent neural network (RNN) or a convolutional neural network (CNN). However, these approaches have drawbacks. The GCN assumes that the predefined graph structure accurately represents genuine dependency relationships, overlooking nuanced situations where connections do not imply true inter-dependencies. Also, capturing temporal dependencies with RNNs or CNNs can be slow and computationally inefficient when considering longer sequences. \n",
        "\n",
        "We introduce the Graph WaveNet framework to tackle these shortcomings and effectively represent Spatial-temporal graphs using Graph Wavenet Framework to forecast the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "d88afdbb-d1e7-4e12-e478-0608d13c663b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1.html\n",
            "Requirement already satisfied: torch-scatter in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1.html\n",
            "Requirement already satisfied: torch-sparse in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.6.18)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-sparse) (1.10.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scipy->torch-sparse) (1.24.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: torch-geometric in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.4.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: requests in /Users/mmajid/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (1.24.1)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (1.10.0)\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (1.2.1)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (4.58.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (1.26.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "import torch\n",
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip3 install torch-scatter -f $scatter_src\n",
        "!pip3 install torch-sparse -f $sparse_src\n",
        "!pip3 install torch-geometric\n",
        "!pip3 install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip3 install -U -q PyDrive\n",
        "\n",
        "!python3 -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "e9021bd9-0717-4186-a0b4-7ada8fe6a5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "2.4.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "import torch_geometric\n",
        "print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph WaveNet Framework - Our Implementation\n",
        "Our implementation of Graph WaveNet Framework is located at https://github.com/ggaoshen/graph_wavenet.git. We import the `GraphWaveNet` model from our repo and load it to the Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Re1G-ZlcQP",
        "outputId": "433f5ec2-4db9-4f23-de73-f1e98f2bca74"
      },
      "outputs": [],
      "source": [
        "# Import GraphWaveNet module\n",
        "!git clone https://github.com/ggaoshen/graph_wavenet.git\n",
        "%load graph_wavenet/src/graphwavenet.py\n",
        "import sys\n",
        "sys.path.append('graph_wavenet/src/')\n",
        "from graphwavenet import GraphWaveNet\n",
        "import util as util\n",
        "from util import masked_mse, temporal_dataset_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch Geometric Temporal\n",
        "PyTorch Geometric Temporal is a temporal graph neural network extension library for PyTorch Geometric. It builds on open-source deep-learning and graph processing libraries. It is the first open-source library for temporal deep learning on geometric structures and provides constant time difference graph neural networks on dynamic and static graphs.\n",
        "We install the PGT library to gain access to its strucures, functions and datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGgtAIg9lcQP",
        "outputId": "f4568942-dc52-4b6b-980e-923688a5ed1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-geometric-temporal in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.54.0)\n",
            "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (1.16.0)\n",
            "Requirement already satisfied: torch-geometric in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (2.4.0)\n",
            "Requirement already satisfied: decorator==4.4.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (3.1)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (1.24.1)\n",
            "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (1.13.1)\n",
            "Requirement already satisfied: cython in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (3.0.6)\n",
            "Requirement already satisfied: torch-scatter in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (2.1.2)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (1.3.5)\n",
            "Requirement already satisfied: torch-sparse in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric-temporal) (0.6.18)\n",
            "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas<=1.3.5->torch-geometric-temporal) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch->torch-geometric-temporal) (4.4.0)\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric->torch-geometric-temporal) (1.2.1)\n",
            "Requirement already satisfied: requests in /Users/mmajid/Library/Python/3.9/lib/python/site-packages (from torch-geometric->torch-geometric-temporal) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric->torch-geometric-temporal) (5.9.4)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric->torch-geometric-temporal) (3.1.1)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric->torch-geometric-temporal) (3.1.2)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric->torch-geometric-temporal) (4.58.0)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric->torch-geometric-temporal) (1.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch-geometric->torch-geometric-temporal) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric->torch-geometric-temporal) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric->torch-geometric-temporal) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric->torch-geometric-temporal) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric->torch-geometric-temporal) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->torch-geometric->torch-geometric-temporal) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->torch-geometric->torch-geometric-temporal) (3.1.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hungarian Chickenpox Dataset\n",
        "PyTorch Geometric Temporal (PGT) provides the Chickenpox Cases in Hungary dataset, which shares the reported cases of chickenpox in Hungary by county on a weekly basis between 2005 and 2015, with (20) nodes representing counties and (61) undirected edges representing a “neighboring” relationship.  This is an example of a static graph with temporal signals.  The graph structure represents the regional geography, which is fixed, while the node features represent the number of cases of the disease, which varies over time. Further information on the dataset and its significance can be found at https://arxiv.org/abs/2102.08100.\n",
        "\n",
        "This colab will use our Graph WaveNet Framework to represent the Hungarian Chickenpox Dataset and learn to predict cases over a 10 week forecast. To do so, we download the dataset from PGT below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHipsw6jF91T",
        "outputId": "0259d7ec-04bd-476d-b24d-dda4234351bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n",
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "dataset = ChickenpoxDatasetLoader().get_dataset(lags=8) # consistent with chickenpox paper\n",
        "iterator = iter(dataset)\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import all the necessary PyTorch libraries for training the Graph WaveNet Framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# training\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache() # clear cuda cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Temporal Signal Split\n",
        "This is an essential feature provided by PGT that helps to break the down in to training, validation, and testing datasets along the temporal dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ratio, val_ratio = 0.7, 0.1\n",
        "train_dataset, val_dataset, test_dataset = temporal_dataset_split(dataset, train_split = train_ratio, validation_split = val_ratio)\n",
        "val_offset = int(dataset.snapshot_count * train_ratio) # starting index for valid set\n",
        "test_offset = val_offset+int(dataset.snapshot_count * val_ratio) # starting index for valid set\n",
        "\n",
        "def prepare_n_period_y(dataset):\n",
        "\n",
        "    res = []\n",
        "    for data in dataset:\n",
        "        res.append(data.y)\n",
        "    res = torch.stack(res, dim=0)\n",
        "\n",
        "    return res\n",
        "\n",
        "y_all = prepare_n_period_y(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_dim = dataset[0].num_node_features # 8 treat lagged inputs as node features\n",
        "out_dim = 1\n",
        "num_nodes = dataset[0].num_nodes # 20\n",
        "timesteps_to_predict = 10 # 10, 20, 40 week forecast horizon\n",
        "epochs = 200\n",
        "lrate = 0.0001\n",
        "wdecay = 0.001\n",
        "\n",
        "# early stopping parameters\n",
        "patience = 10\n",
        "counter = 0\n",
        "best_val_loss = float('inf') \n",
        "\n",
        "save_path = \"store/checkpoint\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph Wavenet - Extension\n",
        "To further improve our Graph WaveNet Framework, we introduced an extension framework to boost its performace while training on the Hungrarian Small Pox data set. Some key etension features include adding skip connections within the spatial temporal layers and introducing a learning rate decay scheduler.\n",
        "`util.extensions_enabled` flag controls the enablement of extensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph Wavenet - Extensions Enabled: True\n"
          ]
        }
      ],
      "source": [
        "# util.extensions_enabled controls the extensions that have been introduced to improve \n",
        "# the performance of Graph Wavenet. To turn off the extensions, set the below flag to False\n",
        "util.extensions_enabled = True\n",
        "print(\"Graph Wavenet - Extensions Enabled: {}\".format(util.extensions_enabled))\n",
        "if util.extensions_enabled:\n",
        "    epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### GraphWaveNet\n",
        "This is our implementation of the framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GraphWaveNet(\n",
        "    num_nodes=num_nodes,\n",
        "    in_channels=in_dim,\n",
        "    out_channels=out_dim,\n",
        "    out_timesteps=timesteps_to_predict,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Graph WaveNet Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9927649475416184\n",
            "Epoch: 050, Train Loss: 0.9928, Valid Loss: 0.8144, Training Time: 9.2988/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:09<08:04,  9.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9743932186675188\n",
            "Epoch: 050, Train Loss: 0.9744, Valid Loss: 0.8099, Training Time: 9.1238/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 2/50 [00:19<07:49,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9668276639017056\n",
            "Epoch: 050, Train Loss: 0.9668, Valid Loss: 0.8079, Training Time: 9.5505/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 3/50 [00:29<07:49,  9.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9631220695762415\n",
            "Epoch: 050, Train Loss: 0.9631, Valid Loss: 0.8075, Training Time: 9.1801/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 4/50 [00:39<07:36,  9.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9605597644048149\n",
            "Epoch: 050, Train Loss: 0.9606, Valid Loss: 0.8071, Training Time: 9.4127/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5/50 [00:49<07:27,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9587598632668303\n",
            "Epoch: 050, Train Loss: 0.9588, Valid Loss: 0.8056, Training Time: 9.0638/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 6/50 [00:59<07:13,  9.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9570951011177142\n",
            "Epoch: 050, Train Loss: 0.9571, Valid Loss: 0.8061, Training Time: 9.0275/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 7/50 [01:08<06:59,  9.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9570089809254102\n",
            "Epoch: 050, Train Loss: 0.9570, Valid Loss: 0.8065, Training Time: 9.0222/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 8/50 [01:18<06:47,  9.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9561041787079948\n",
            "Epoch: 050, Train Loss: 0.9561, Valid Loss: 0.8063, Training Time: 9.2075/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 9/50 [01:28<06:39,  9.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9561237550410636\n",
            "Epoch: 050, Train Loss: 0.9561, Valid Loss: 0.8058, Training Time: 9.2672/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 10/50 [01:38<06:31,  9.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9550637062120155\n",
            "Epoch: 050, Train Loss: 0.9551, Valid Loss: 0.8051, Training Time: 9.3476/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 11/50 [01:48<06:23,  9.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9556152909672443\n",
            "Epoch: 050, Train Loss: 0.9556, Valid Loss: 0.8056, Training Time: 9.3790/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 12/50 [01:58<06:15,  9.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9551728466593123\n",
            "Epoch: 050, Train Loss: 0.9552, Valid Loss: 0.8051, Training Time: 9.0643/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 13/50 [02:07<06:02,  9.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9545262028777085\n",
            "Epoch: 050, Train Loss: 0.9545, Valid Loss: 0.8053, Training Time: 9.3837/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 14/50 [02:17<05:54,  9.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546635651903896\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8058, Training Time: 9.1056/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 15/50 [02:27<05:43,  9.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9548705985826702\n",
            "Epoch: 050, Train Loss: 0.9549, Valid Loss: 0.8060, Training Time: 9.3074/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 16/50 [02:37<05:34,  9.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546551536042295\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8061, Training Time: 9.1902/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 17/50 [02:47<05:24,  9.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9547218771542431\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8054, Training Time: 9.2761/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 18/50 [02:57<05:15,  9.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546897810336441\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8054, Training Time: 9.1391/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 19/50 [03:06<05:04,  9.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9549726633806415\n",
            "Epoch: 050, Train Loss: 0.9550, Valid Loss: 0.8062, Training Time: 9.2131/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 20/50 [03:16<04:54,  9.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9545375569191733\n",
            "Epoch: 050, Train Loss: 0.9545, Valid Loss: 0.8056, Training Time: 9.2047/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 21/50 [03:26<04:44,  9.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9544355299707741\n",
            "Epoch: 050, Train Loss: 0.9544, Valid Loss: 0.8069, Training Time: 9.0966/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 22/50 [03:36<04:33,  9.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9549561853320818\n",
            "Epoch: 050, Train Loss: 0.9550, Valid Loss: 0.8047, Training Time: 9.3393/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 23/50 [03:45<04:25,  9.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.954543543242769\n",
            "Epoch: 050, Train Loss: 0.9545, Valid Loss: 0.8061, Training Time: 9.1239/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 24/50 [03:55<04:14,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546057310027997\n",
            "Epoch: 050, Train Loss: 0.9546, Valid Loss: 0.8053, Training Time: 9.1158/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 25/50 [04:05<04:03,  9.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546843269647911\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8060, Training Time: 9.1143/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 26/50 [04:15<03:53,  9.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9547584872474909\n",
            "Epoch: 050, Train Loss: 0.9548, Valid Loss: 0.8058, Training Time: 9.1017/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 27/50 [04:24<03:43,  9.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9545209251894177\n",
            "Epoch: 050, Train Loss: 0.9545, Valid Loss: 0.8067, Training Time: 9.1591/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 28/50 [04:34<03:34,  9.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546491822336792\n",
            "Epoch: 050, Train Loss: 0.9546, Valid Loss: 0.8054, Training Time: 9.1188/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 29/50 [04:44<03:24,  9.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9548923716229234\n",
            "Epoch: 050, Train Loss: 0.9549, Valid Loss: 0.8058, Training Time: 9.1218/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 30/50 [04:53<03:14,  9.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9548580821105448\n",
            "Epoch: 050, Train Loss: 0.9549, Valid Loss: 0.8057, Training Time: 9.1164/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 31/50 [05:03<03:04,  9.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9550976565361936\n",
            "Epoch: 050, Train Loss: 0.9551, Valid Loss: 0.8059, Training Time: 9.1073/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 32/50 [05:13<02:54,  9.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9541633569772944\n",
            "Epoch: 050, Train Loss: 0.9542, Valid Loss: 0.8053, Training Time: 9.1731/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 33/50 [05:23<02:45,  9.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9547396699449145\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8046, Training Time: 9.1085/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 34/50 [05:32<02:35,  9.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9548809149076846\n",
            "Epoch: 050, Train Loss: 0.9549, Valid Loss: 0.8061, Training Time: 9.1442/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 35/50 [05:42<02:25,  9.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9548185240933905\n",
            "Epoch: 050, Train Loss: 0.9548, Valid Loss: 0.8059, Training Time: 9.0971/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 36/50 [05:52<02:15,  9.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546853472377513\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8057, Training Time: 9.1538/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 37/50 [06:01<02:06,  9.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9547389486187182\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8064, Training Time: 9.0667/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 38/50 [06:11<01:56,  9.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9547460455302159\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8065, Training Time: 9.1292/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 39/50 [06:21<01:46,  9.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.955001758110598\n",
            "Epoch: 050, Train Loss: 0.9550, Valid Loss: 0.8058, Training Time: 9.1133/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 40/50 [06:31<01:37,  9.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9544376974930587\n",
            "Epoch: 050, Train Loss: 0.9544, Valid Loss: 0.8058, Training Time: 9.1812/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 41/50 [06:40<01:27,  9.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9548788438953231\n",
            "Epoch: 050, Train Loss: 0.9549, Valid Loss: 0.8058, Training Time: 9.1915/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 42/50 [06:50<01:17,  9.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546233720942543\n",
            "Epoch: 050, Train Loss: 0.9546, Valid Loss: 0.8066, Training Time: 9.2075/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 43/50 [07:00<01:08,  9.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9548615436575539\n",
            "Epoch: 050, Train Loss: 0.9549, Valid Loss: 0.8051, Training Time: 9.5170/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 44/50 [07:10<00:59,  9.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9550407938866728\n",
            "Epoch: 050, Train Loss: 0.9550, Valid Loss: 0.8063, Training Time: 9.1681/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 45/50 [07:20<00:49,  9.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9547290147845128\n",
            "Epoch: 050, Train Loss: 0.9547, Valid Loss: 0.8058, Training Time: 9.5247/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 46/50 [07:30<00:39,  9.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9544341633236425\n",
            "Epoch: 050, Train Loss: 0.9544, Valid Loss: 0.8052, Training Time: 9.1990/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 47/50 [07:40<00:29,  9.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9545794742851205\n",
            "Epoch: 050, Train Loss: 0.9546, Valid Loss: 0.8056, Training Time: 9.1246/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 48/50 [07:49<00:19,  9.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9545765979511243\n",
            "Epoch: 050, Train Loss: 0.9546, Valid Loss: 0.8057, Training Time: 9.1303/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 49/50 [07:59<00:09,  9.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9546116334347257\n",
            "Epoch: 050, Train Loss: 0.9546, Valid Loss: 0.8072, Training Time: 9.1207/epoch\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [08:09<00:00,  9.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Time: 9.1926 secs/epoch\n",
            "Average Inference Time: 0.5887 secs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"start training...\", flush=True)\n",
        "his_loss = []\n",
        "val_time = []\n",
        "train_time = []\n",
        "best_epoch = 0\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "\n",
        "scheduler = None\n",
        "clip = None\n",
        "\n",
        "# As part of extensions, we enable learning rate decay and gradient clipping\n",
        "if util.extensions_enabled:\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.99)\n",
        "    clip = 5\n",
        "\n",
        "model.train()\n",
        "\n",
        "training_curve_dict = {\"epoch_train_loss\": [], \"epoch_valid_loss\": []}\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = []\n",
        "    t1 = time.time()\n",
        "\n",
        "    for i, snapshot in enumerate(train_dataset):\n",
        "        x_train = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "        if timesteps_to_predict == 1:\n",
        "            y_train = snapshot.y.to(device)\n",
        "        else:\n",
        "            y_train = y_all[i : i + timesteps_to_predict,:].to(device)\n",
        "\n",
        "        pred = model(x_train, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "        loss = masked_mse(pred, y_train, 0.0) # mean squared error for loss\n",
        "        loss.backward()\n",
        "        if util.extensions_enabled:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if util.extensions_enabled:\n",
        "            scheduler.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "    mtrain_loss = np.mean(train_loss)\n",
        "    training_curve_dict['epoch_train_loss'].append(mtrain_loss)\n",
        "    print(f\"training loss: {mtrain_loss}\")\n",
        "\n",
        "\n",
        "    t2 = time.time()\n",
        "    train_time.append(t2 - t1)\n",
        "    valid_loss = []\n",
        "\n",
        "    s1 = time.time()\n",
        "    for i, snapshot in enumerate(val_dataset):\n",
        "        x_val = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "        if timesteps_to_predict == 1:\n",
        "            y_val = snapshot.y.to(device)\n",
        "        else:\n",
        "            y_val = y_all[val_offset + i : val_offset + i + timesteps_to_predict,:].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model(x_val, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "        loss = masked_mse(pred, y_val, 0.0).cpu().numpy()\n",
        "        valid_loss.append(loss)\n",
        "\n",
        "    s2 = time.time()\n",
        "    # log = \"Epoch: {:03d}, Inference Time: {:.4f} secs\"\n",
        "    # print(log.format(i, (s2 - s1)))\n",
        "    val_time.append(s2 - s1)\n",
        "\n",
        "    mvalid_loss = np.mean(valid_loss)\n",
        "    training_curve_dict['epoch_valid_loss'].append(mvalid_loss)\n",
        "\n",
        "    his_loss.append(mvalid_loss)\n",
        "\n",
        "    if np.argmin(his_loss) == len(his_loss) - 1:\n",
        "        torch.save(\n",
        "            model.state_dict(), save_path + \"/epoch_\" + str(i) + \".pth\"\n",
        "        )\n",
        "        best_epoch = i\n",
        "\n",
        "    log = (\n",
        "        \"Epoch: {:03d}, Train Loss: {:.4f}, \"\n",
        "        + \"Valid Loss: {:.4f}, \"\n",
        "        + \"Training Time: {:.4f}/epoch\"\n",
        "    )\n",
        "    print(\n",
        "        log.format(\n",
        "            i,\n",
        "            mtrain_loss,\n",
        "            mvalid_loss,\n",
        "            (t2 - t1),\n",
        "        ),\n",
        "        flush=True,\n",
        "    )\n",
        "print(\"Average Training Time: {:.4f} secs/epoch\".format(np.mean(train_time)))\n",
        "print(\"Average Inference Time: {:.4f} secs\".format(np.mean(val_time)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Graph WaveNet Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE Loss: 0.9697\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# eval\n",
        "model.load_state_dict(\n",
        "    torch.load(save_path + \"/epoch_\" + str(best_epoch) + \".pth\")\n",
        ")\n",
        "model.eval()\n",
        "loss = 0\n",
        "for i, snapshot in enumerate(test_dataset[:-timesteps_to_predict]):\n",
        "\n",
        "    x_test = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "    \n",
        "    if timesteps_to_predict == 1:\n",
        "        y_test = snapshot.y.to(device)\n",
        "    else:\n",
        "        y_test = y_all[test_offset+i : test_offset+i + timesteps_to_predict,:].to(device)\n",
        "        \n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(x_test, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "    loss += masked_mse(pred, y_test, 0.0) # mean squared error as loss\n",
        "\n",
        "loss = loss / (i+1)\n",
        "loss = loss.item()\n",
        "print(\"Test MSE Loss: {:.4f}\".format(loss))\n",
        "\n",
        "\n",
        "# store training loss \n",
        "df = pd.DataFrame(training_curve_dict)\n",
        "df.to_csv(\"training_curve.csv\")\n",
        "\n",
        "\n",
        "# plot training and validation loss\n",
        "df.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "rW_Gc1oQ8rNC",
        "outputId": "c5d9ba7e-e8ae-44ba-b030-478ad0ecf948"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('training_curve.csv')\n",
        "training_curve_dict[\"epoch_train_loss\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
