{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggaoshen/graph_wavenet/blob/sg-experiment/CS224W_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Final Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "Description goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "You might need to use GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J_m9l6OYCQZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18a26db-006c-478d-8ad4-c09668d527bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu118\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "import torch\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  torch_version = str(torch.__version__)\n",
        "  scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "  sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "  !pip install torch-scatter -f $scatter_src\n",
        "  !pip install torch-sparse -f $sparse_src\n",
        "  !pip install torch-geometric\n",
        "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "  !pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qpr0ThDgZmZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b4764b-9b8f-4349-beb0-370be329663f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "11.8\n"
          ]
        }
      ],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !nvcc --version\n",
        "  !python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PRfgbfTjCRD_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2ed210-0666-414c-ecfd-620b2de8694d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "2.4.0\n"
          ]
        }
      ],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  import torch\n",
        "  print(torch.__version__)\n",
        "  import torch_geometric\n",
        "  print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Re1G-ZlcQP",
        "outputId": "6040c9b6-21c4-4254-a3e6-6338f3529df7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'graph_wavenet'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 159 (delta 88), reused 72 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (159/159), 108.04 KiB | 2.84 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ],
      "source": [
        "# Import GraphWaveNet module\n",
        "!git clone -b mmajid/tgnn-improvements https://github.com/ggaoshen/graph_wavenet.git # NOTE: choose the right branch\n",
        "%load graph_wavenet/src/graphwavenet.py\n",
        "import sys\n",
        "sys.path.append('graph_wavenet/src/')\n",
        "from graphwavenet import GraphWaveNet\n",
        "from util import masked_rmse, masked_mse, masked_mae, masked_mape, metric, temporal_dataset_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGgtAIg9lcQP",
        "outputId": "3487a614-3dc4-4527-fecb-28664c642af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric-temporal\n",
            "  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m884.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.1.0+cu118)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.0.6)\n",
            "Collecting pandas<=1.3.5 (from torch-geometric-temporal)\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (0.6.18+pt21cu118)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.1.2+pt21cu118)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-geometric-temporal) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-geometric-temporal) (1.3.0)\n",
            "Building wheels for collected packages: torch-geometric-temporal\n",
            "  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86722 sha256=2f53a1cdcff26cf23c4c5e0526bc4bd953ab373e0d6610ff0067d6ff51af891a\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n",
            "Successfully built torch-geometric-temporal\n",
            "Installing collected packages: pandas, torch-geometric-temporal\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.15.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5 torch-geometric-temporal-0.54.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "\n",
        "\n",
        "# Temporal Datasets\n",
        "# from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
        "# loader = METRLADatasetLoader()\n",
        "# dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
        "# iterator = iter(dataset)\n",
        "# print(\"METRLADatasetLoader\", next(iterator))\n",
        "# print(\"METRLADatasetLoader\", next(iterator))\n",
        "\n",
        "\n",
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "dataset = ChickenpoxDatasetLoader().get_dataset(lags=8) # consistent with chickenpox paper\n",
        "iterator = iter(dataset)\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))\n",
        "\n",
        "\n",
        "# from torch_geometric_temporal.dataset import WikiMathsDatasetLoader\n",
        "# dataset = WikiMathsDatasetLoader().get_dataset(lags=14)\n",
        "# iterator = iter(dataset)\n",
        "# print(\"WikiMathsDatasetLoader\", next(iterator))\n",
        "# print(\"WikiMathsDatasetLoader\", next(iterator))\n",
        "\n",
        "\n",
        "# from torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\n",
        "# dataset = TwitterTennisDatasetLoader().get_dataset()\n",
        "# print(\"TwitterTennisDatasetLoader\", next(iter(dataset)))\n",
        "\n",
        "\n",
        "# Graph summaries\n",
        "# METRLADatasetLoader Data(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])\n",
        "# ChickenpoxDatasetLoader Data(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n",
        "# WikiMathsDatasetLoader Data(x=[1068, 14], edge_index=[2, 27079], edge_attr=[27079], y=[1068])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHipsw6jF91T",
        "outputId": "9a27d4e1-8e09-44c4-96ea-3520834228bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n",
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Chickenpox Dataset\n",
        "\n",
        "# from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# training\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache() # clear cuda cache\n",
        "\n",
        "# sample training loop\n",
        "train_split, validation_split = 0.6, 0.2\n",
        "train_dataset, val_dataset, test_dataset = temporal_dataset_split(dataset, train_split=train_split, validation_split=validation_split)\n",
        "train_size = int(train_split * dataset.snapshot_count)\n",
        "val_size = int(validation_split * dataset.snapshot_count)\n",
        "val_offset, test_offset = train_size, train_size + val_size # starting index for val and test sets\n",
        "\n",
        "in_dim = dataset[0].num_node_features # 8 treat lagged inputs as node features\n",
        "out_dim = 1 # output size\n",
        "num_nodes = dataset[0].num_nodes # 1068\n",
        "timesteps_to_predict = 10 # 1\n",
        "epochs = 200\n",
        "lrate = 0.0001\n",
        "wdecay = 0.001\n",
        "save_path = \"store/checkpoint\"\n",
        "\n",
        "model = GraphWaveNet(\n",
        "    num_nodes=num_nodes,\n",
        "    in_channels=in_dim,\n",
        "    out_channels=out_dim,\n",
        "    out_timesteps=timesteps_to_predict,\n",
        ").to(device)\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "print(\"start training...\", flush=True)\n",
        "his_loss = []\n",
        "val_time = []\n",
        "train_time = []\n",
        "best_epoch = 0\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "\n",
        "model.train()\n",
        "\n",
        "# def get_temporal_y_label(y_1d, tag=\"train\"):\n",
        "#     \"\"\"\n",
        "#     y_1d: y label at timestep t,\n",
        "#     Return: y label over lookback window [t + 1 - timesteps_to_predict, t]\n",
        "#     \"\"\"\n",
        "#     if timesteps_to_predict == 1:\n",
        "#         return snapshot.y.to(device)\n",
        "#     else:\n",
        "#         y_train = torch.stack([dataset[t].y for t in range(i+1-timesteps_to_predict, i+1)], dim=0).to(device)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = []\n",
        "    t1 = time.time()\n",
        "\n",
        "    for i, snapshot in enumerate(train_dataset):\n",
        "        x_train = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "        # print(\"x_train size:\", x_train.shape)\n",
        "        y_train = snapshot.y.to(device)\n",
        "        pred = model(x_train, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "\n",
        "        # print(pred.size())\n",
        "        # print(y_train.size())\n",
        "        # print(y_train[-1])\n",
        "        # print(snapshot.y)\n",
        "        loss = masked_mse(pred, y_train, 0.0) # mean squared error for loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        # if i % 100 == 0:\n",
        "        #     log = 'Iter: {:05d}, Train Loss: {:.4f}'\n",
        "        #     print(\n",
        "        #         log.format(\n",
        "        #             i,\n",
        "        #             train_loss[-1]), flush=True)\n",
        "\n",
        "\n",
        "    t2 = time.time()\n",
        "    train_time.append(t2 - t1)\n",
        "    valid_loss = []\n",
        "\n",
        "    s1 = time.time()\n",
        "    for i, snapshot in enumerate(val_dataset):\n",
        "        x_val = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "        y_val = snapshot.y.to(device)\n",
        "        pred = model(x_val, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "\n",
        "        loss = masked_mse(pred, y_val, 0.0) # mean squared error for loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        valid_loss.append(loss.item())\n",
        "\n",
        "    s2 = time.time()\n",
        "    log = 'Epoch: {:05d}, Inference Time: {:.4f} secs'\n",
        "    print(log.format(epoch, (s2 - s1)))\n",
        "    val_time.append(s2 - s1)\n",
        "    mtrain_loss = np.mean(train_loss)\n",
        "    mvalid_loss = np.mean(valid_loss)\n",
        "    his_loss.append(mvalid_loss)\n",
        "\n",
        "    if np.argmin(his_loss) == len(his_loss) - 1:\n",
        "        best_epoch = epoch\n",
        "\n",
        "    log = 'Epoch: {:03d}, Train Loss: {:.4f},' + \\\n",
        "        'Valid Loss: {:.4f},' + \\\n",
        "        'Training Time: {:.4f}/epoch'\n",
        "    print(\n",
        "        log.format(epoch, mtrain_loss, mvalid_loss, (t2 - t1)), flush=True)\n",
        "\n",
        "print(\"Average Training Time: {:.4f} secs/epoch\".format(\n",
        "    np.mean(train_time)))\n",
        "print(\"Average Inference Time: {:.4f} secs\".format(np.mean(val_time)))\n",
        "\n",
        "pd.DataFrame({\"train_loss\": train_loss, \"val_loss\": valid_loss}).to_csv(\"training_curve.csv\") # store training and testing loss\n",
        "\n",
        "# eval\n",
        "model.eval()\n",
        "loss = 0\n",
        "for i, snapshot in enumerate(test_dataset):\n",
        "    x_test = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "    y_test = snapshot.y.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(x_test, snapshot.edge_index, snapshot.edge_attr)\n",
        "    loss += masked_mse(pred, y_test, 0.0) # mean absolute error as loss\n",
        "\n",
        "loss = loss / (i+1)\n",
        "loss = loss.item()\n",
        "print(\"MSE: {:.4f}\".format(loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW_Gc1oQ8rNC",
        "outputId": "6c419942-75c3-4a43-9830-f6071247f04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00000, Inference Time: 5.2831 secs\n",
            "Epoch: 000, Train Loss: 0.8733,Valid Loss: 0.6162,Training Time: 14.0189/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/200 [00:19<1:04:01, 19.30s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00001, Inference Time: 4.3150 secs\n",
            "Epoch: 001, Train Loss: 0.7433,Valid Loss: 0.5889,Training Time: 14.7616/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  1%|          | 2/200 [00:38<1:03:16, 19.17s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00002, Inference Time: 4.8915 secs\n",
            "Epoch: 002, Train Loss: 0.7131,Valid Loss: 0.5676,Training Time: 14.7546/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 3/200 [00:58<1:03:40, 19.39s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00003, Inference Time: 4.3920 secs\n",
            "Epoch: 003, Train Loss: 0.6927,Valid Loss: 0.5534,Training Time: 13.9480/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 4/200 [01:16<1:01:59, 18.98s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00004, Inference Time: 4.9316 secs\n",
            "Epoch: 004, Train Loss: 0.6830,Valid Loss: 0.5557,Training Time: 16.7363/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▎         | 5/200 [01:38<1:04:50, 19.95s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00005, Inference Time: 4.2882 secs\n",
            "Epoch: 005, Train Loss: 0.6708,Valid Loss: 0.5493,Training Time: 14.0309/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 6/200 [01:56<1:02:43, 19.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00006, Inference Time: 4.2834 secs\n",
            "Epoch: 006, Train Loss: 0.6610,Valid Loss: 0.5424,Training Time: 13.6770/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▎         | 7/200 [02:14<1:00:53, 18.93s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00007, Inference Time: 5.0008 secs\n",
            "Epoch: 007, Train Loss: 0.6549,Valid Loss: 0.5331,Training Time: 13.7769/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 8/200 [02:33<1:00:25, 18.88s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 00008, Inference Time: 4.3093 secs\n",
            "Epoch: 008, Train Loss: 0.6442,Valid Loss: 0.5293,Training Time: 13.5975/epoch\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 9/200 [02:51<59:08, 18.58s/it]  "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "NcsS-FdiPrRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset GPU RAM if GPU out of memory\n",
        "\n",
        "# !pip install numba\n",
        "\n",
        "# from numba import cuda\n",
        "\n",
        "# cuda.select_device(0) # choosing second GPU\n",
        "\n",
        "# cuda.close()"
      ],
      "metadata": {
        "id": "GU0OV1AJUVCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yi58dfonTQG3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}