{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggaoshen/graph_wavenet/blob/sg-experiment/CS224W_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Final Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "Description goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSaetj53YnT6"
      },
      "source": [
        "# Device\n",
        "You might need to use GPU for this Colab.\n",
        "\n",
        "Please click `Runtime` and then `Change runtime type`. Then set the `hardware accelerator` to **GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "01304616-57c9-4b22-fcfb-179cec57519e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_scatter-2.1.2%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt21cu118\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.1.0+cu118.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcu118/torch_sparse-0.6.18%2Bpt21cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.23.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt21cu118\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "import torch\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  torch_version = str(torch.__version__)\n",
        "  scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "  sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "  !pip install torch-scatter -f $scatter_src\n",
        "  !pip install torch-sparse -f $sparse_src\n",
        "  !pip install torch-geometric\n",
        "  !pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "  !pip install -U -q PyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpr0ThDgZmZV",
        "outputId": "1c04e901-4d0f-4d16-bcc1-a6a68bbc99a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n",
            "11.8\n"
          ]
        }
      ],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  !nvcc --version\n",
        "  !python -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "b04e90ae-f116-4075-a2e4-9fd973dd662a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.1.0+cu118\n",
            "2.4.0\n"
          ]
        }
      ],
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "  import torch\n",
        "  print(torch.__version__)\n",
        "  import torch_geometric\n",
        "  print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Re1G-ZlcQP",
        "outputId": "62e3475e-e4bc-45c8-9d2f-46f7aad8a78a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'graph_wavenet'...\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 169 (delta 95), reused 88 (delta 40), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (169/169), 116.84 KiB | 1.20 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n"
          ]
        }
      ],
      "source": [
        "# Import GraphWaveNet module\n",
        "!git clone -b mmajid-experiment https://github.com/ggaoshen/graph_wavenet.git # NOTE: choose the right branch\n",
        "%load graph_wavenet/src/graphwavenet.py\n",
        "import sys\n",
        "sys.path.append('graph_wavenet/src/')\n",
        "from graphwavenet import GraphWaveNet\n",
        "import util as util\n",
        "from util import masked_rmse, masked_mse, masked_mae, masked_mape, metric, temporal_dataset_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGgtAIg9lcQP",
        "outputId": "e66f5e5b-af4d-4be9-899c-2702967dd5c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-geometric-temporal\n",
            "  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m698.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.1.0+cu118)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.0.6)\n",
            "Collecting pandas<=1.3.5 (from torch-geometric-temporal)\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (0.6.18+pt21cu118)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.1.2+pt21cu118)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-geometric-temporal) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-geometric-temporal) (1.3.0)\n",
            "Building wheels for collected packages: torch-geometric-temporal\n",
            "  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86722 sha256=6bf0cdd7012e3fff2e1c2fa5a57157c9466202ee9443fd46b61adeeea3d02eaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n",
            "Successfully built torch-geometric-temporal\n",
            "Installing collected packages: pandas, torch-geometric-temporal\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.15.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5 torch-geometric-temporal-0.54.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHipsw6jF91T",
        "outputId": "76b50da2-8d8a-4645-fd91-22873698a387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n",
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "\n",
        "\n",
        "# Temporal Datasets\n",
        "# from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
        "# loader = METRLADatasetLoader()\n",
        "# dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=12)\n",
        "# iterator = iter(dataset)\n",
        "# print(\"METRLADatasetLoader\", next(iterator))\n",
        "# print(\"METRLADatasetLoader\", next(iterator))\n",
        "\n",
        "\n",
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "dataset = ChickenpoxDatasetLoader().get_dataset(lags=8) # consistent with chickenpox paper\n",
        "iterator = iter(dataset)\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))\n",
        "\n",
        "\n",
        "# from torch_geometric_temporal.dataset import WikiMathsDatasetLoader\n",
        "# dataset = WikiMathsDatasetLoader().get_dataset(lags=14)\n",
        "# iterator = iter(dataset)\n",
        "# print(\"WikiMathsDatasetLoader\", next(iterator))\n",
        "# print(\"WikiMathsDatasetLoader\", next(iterator))\n",
        "\n",
        "\n",
        "# from torch_geometric_temporal.dataset import TwitterTennisDatasetLoader\n",
        "# dataset = TwitterTennisDatasetLoader().get_dataset()\n",
        "# print(\"TwitterTennisDatasetLoader\", next(iter(dataset)))\n",
        "\n",
        "\n",
        "# Graph summaries\n",
        "# METRLADatasetLoader Data(x=[207, 2, 12], edge_index=[2, 1722], edge_attr=[1722], y=[207, 12])\n",
        "# ChickenpoxDatasetLoader Data(x=[20, 4], edge_index=[2, 102], edge_attr=[102], y=[20])\n",
        "# WikiMathsDatasetLoader Data(x=[1068, 14], edge_index=[2, 27079], edge_attr=[27079], y=[1068])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rW_Gc1oQ8rNC",
        "outputId": "3165e2c3-8096-4a98-ed09-fa0b034fcf63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 1/10 [00:26<03:59, 26.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9703844988190955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:51<03:26, 25.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.95704825073661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [01:17<03:01, 25.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.951991951503491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [01:44<02:36, 26.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9504689416480555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 5/10 [02:09<02:09, 25.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9484454917543303\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [02:35<01:43, 25.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9472007512387799\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [03:01<01:17, 25.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9460940116127957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 8/10 [03:27<00:51, 25.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9458359803364006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [03:53<00:25, 25.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9447877772792849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [04:19<00:00, 25.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9447196852235399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.9595\n"
          ]
        }
      ],
      "source": [
        "# Run Chickenpox Dataset\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# training\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache() # clear cuda cache\n",
        "\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "train_ratio = 0.8\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=train_ratio)\n",
        "offset = int(dataset.snapshot_count * train_ratio) # starting index for test set\n",
        "\n",
        "in_dim = dataset[0].num_node_features # 8 treat lagged inputs as node features\n",
        "out_dim = 1 # output size\n",
        "num_nodes = dataset[0].num_nodes # 1068\n",
        "timesteps_to_predict = 10 # 1\n",
        "epochs = 10\n",
        "lrate = 0.0001\n",
        "wdecay = 0.001\n",
        "save_path = \"store/checkpoint\"\n",
        "\n",
        "util.extensions_enabled = True\n",
        "print(\"Graph Wavenet Extension for Performance Improvements: {}\".format(util.extensions_enabled))\n",
        "\n",
        "model = GraphWaveNet(\n",
        "    num_nodes=num_nodes,\n",
        "    in_channels=in_dim,\n",
        "    out_channels=out_dim,\n",
        "    out_timesteps=timesteps_to_predict,\n",
        ").to(device)\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "print(\"start training...\", flush=True)\n",
        "his_loss = []\n",
        "val_time = []\n",
        "train_time = []\n",
        "best_epoch = 0\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "scheduler = None\n",
        "if util.extensions_enabled:\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.03)\n",
        "clip = 5\n",
        "if util.extensions_enabled:\n",
        "    clip = 3\n",
        "\n",
        "model.train()\n",
        "\n",
        "def prepare_n_period_y(dataset):\n",
        "\n",
        "    res = []\n",
        "    for data in dataset:\n",
        "        res.append(data.y)\n",
        "    res = torch.stack(res, dim=0)\n",
        "\n",
        "    return res\n",
        "\n",
        "y_all = prepare_n_period_y(dataset)\n",
        "training_curve_dict = {\"epoch_train_loss\": [], \"epoch_val_loss\": []}\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = []\n",
        "    t1 = time.time()\n",
        "\n",
        "    for i, snapshot in enumerate(train_dataset):\n",
        "        x_train = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "        # print(\"x_train size:\", x_train.shape)\n",
        "        if timesteps_to_predict == 1:\n",
        "            y_train = snapshot.y.to(device)\n",
        "        else:\n",
        "            y_train = y_all[i : i + timesteps_to_predict,:].to(device)\n",
        "\n",
        "        pred = model(x_train, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "        # print(pred.size())\n",
        "        # print(y_all[i : i + timesteps_to_predict,:].size())\n",
        "        loss = masked_mse(pred, y_train, 0.0) # mean squared error for loss\n",
        "        loss.backward()\n",
        "        if util.extensions_enabled:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        if util.extensions_enabled:\n",
        "            scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        # if i % 100 == 0:\n",
        "        #     log = 'Iter: {:05d}, Train Loss: {:.4f}, '\n",
        "        #     print(\n",
        "        #         log.format(i, train_loss[-1]), flush=True)\n",
        "    mtrainloss = np.mean(train_loss)\n",
        "    training_curve_dict['epoch_train_loss'].append(mtrainloss)\n",
        "    print(f\"training loss: {mtrainloss}\")\n",
        "\n",
        "\n",
        "print(\"Average Training Time: {:.4f} secs/epoch\".format(\n",
        "    np.mean(train_time)))\n",
        "\n",
        "pd.DataFrame(training_curve_dict).to_csv(\"training_curve.csv\") # store training and testing loss\n",
        "\n",
        "from google.colab import files\n",
        "files.download('training_curve.csv')\n",
        "\n",
        "\n",
        "# eval\n",
        "model.eval()\n",
        "loss = 0\n",
        "for i, snapshot in enumerate(test_dataset):\n",
        "    if i + timesteps_to_predict > test_dataset.snapshot_count:\n",
        "        break\n",
        "\n",
        "    x_test = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "\n",
        "    if timesteps_to_predict == 1:\n",
        "        y_test = snapshot.y.to(device)\n",
        "    else:\n",
        "        y_test = y_all[offset+i : offset+i + timesteps_to_predict,:].to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(x_test, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "    loss += masked_mse(pred, y_test, 0.0) # mean squared error as loss\n",
        "\n",
        "loss = loss / (i+1)\n",
        "loss = loss.item()\n",
        "print(\"Test MSE Loss: {:.4f}\".format(loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcsS-FdiPrRU"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU0OV1AJUVCT"
      },
      "outputs": [],
      "source": [
        "# Reset GPU RAM if GPU out of memory\n",
        "\n",
        "# !pip install numba\n",
        "\n",
        "# from numba import cuda\n",
        "\n",
        "# cuda.select_device(0) # choosing second GPU\n",
        "\n",
        "# cuda.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi58dfonTQG3",
        "outputId": "c9f110b8-0519-485f-a60b-5e22d284ebdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n",
            "torch.Size([20])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch_geometric_temporal.signal.static_graph_temporal_signal.StaticGraphTemporalSignal at 0x7e0f03fb4e20>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_temporal_y_label(dataset, tag=\"train\"):\n",
        "    \"\"\"\n",
        "    snap_idx: y label index,\n",
        "    Return: y label over forecast horizon [t, t + timesteps_to_predict]\n",
        "    \"\"\"\n",
        "    if timesteps_to_predict == 1:\n",
        "        return dataset\n",
        "\n",
        "    for snap_idx in range(dataset.snapshot_count - timesteps_to_predict + 1):\n",
        "        dataset[snap_idx].y = torch.stack([dataset[t].y for t in range(snap_idx, min(dataset.snapshot_count, snap_idx + timesteps_to_predict))], dim=0)\n",
        "        print(dataset[snap_idx].y.shape)\n",
        "    return dataset\n",
        "\n",
        "dataset1 = get_temporal_y_label(dataset)\n",
        "dataset1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BEUIeTYk6_G",
        "outputId": "4174f172-2a4d-41f3-9ed5-601e7f4a499e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 2.1339, -0.1852,  1.8502,  1.6006, -0.0801, -0.0312, -0.9983,  1.9281,\n",
              "        -2.1279, -1.0767,  1.8773,  1.3354, -0.3223,  0.3702, -2.0845, -0.5332,\n",
              "         0.4694,  1.8230, -0.2246,  0.5254])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0].y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lrZ5ui-k8LF",
        "outputId": "8ce08732-69dd-4bc6-8325-494602ec7aef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 20])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.stack([dataset[t].y for t in range(0, min(dataset.snapshot_count, 0 + timesteps_to_predict))], dim=0).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubuMXaeztdP6",
        "outputId": "c2d663d7-b785-4a84-e6b2-63db0fa6f5ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 10])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_tensors[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymniQRADuNzY",
        "outputId": "0d942a5b-4525-4e6c-a110-df19ce7ce178"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 20])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De8uE446wb5k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
