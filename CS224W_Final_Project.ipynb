{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W: Final Project**\n",
        "# Graph WaveNet for Deep Spatial-Temporal Graph Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "Spatial-temporal graph modeling is a technique used to analyze and understand complex systems, particularly those with varying behaviors across both spatial (how different components or nodes are related in space) and temporal (how these relationships change over time) dimensions. With the advent of graph neural networks, spatial-temporal graph modeling has received increased attention due to its applicability in diverse problem spaces, encompassing areas like traffic speed forecasting, taxi demand prediction, human action recognition, and more.\n",
        "\n",
        "However, capturing spatial and temporal dependencies simultaneously can be challenging. Recent research has explored integrating graph convolution networks (GCN) into either a recurrent neural network (RNN) or a convolutional neural network (CNN). However, these approaches have drawbacks. The GCN assumes that the predefined graph structure accurately represents genuine dependency relationships, overlooking nuanced situations where connections do not imply true inter-dependencies. Also, capturing temporal dependencies with RNNs or CNNs can be slow and computationally inefficient when considering longer sequences. \n",
        "\n",
        "We introduce the Graph WaveNet framework to tackle these shortcomings and effectively represent Spatial-temporal graphs using Graph Wavenet Framework to forecast the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67gOQITlCNQi"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_m9l6OYCQZP",
        "outputId": "d88afdbb-d1e7-4e12-e478-0608d13c663b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1.html\n",
            "Requirement already satisfied: torch-scatter in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.1.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.13.1.html\n",
            "Requirement already satisfied: torch-sparse in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.6.18)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-sparse) (1.10.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scipy->torch-sparse) (1.24.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: torch-geometric in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.4.0)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (1.2.1)\n",
            "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (4.58.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: pyparsing in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (1.24.1)\n",
            "Requirement already satisfied: requests in /Users/mmajid/Library/Python/3.9/lib/python/site-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch-geometric) (1.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch-geometric) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (1.26.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "import torch\n",
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip3 install torch-scatter -f $scatter_src\n",
        "!pip3 install torch-sparse -f $sparse_src\n",
        "!pip3 install torch-geometric\n",
        "!pip3 install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip3 install -U -q PyDrive\n",
        "\n",
        "!python3 -c \"import torch; print(torch.version.cuda)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRfgbfTjCRD_",
        "outputId": "e9021bd9-0717-4186-a0b4-7ada8fe6a5d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.13.1\n",
            "2.4.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "import torch_geometric\n",
        "print(torch_geometric.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph WaveNet Framework - Our Implementation\n",
        "Our implementation of Graph WaveNet Framework is located at https://github.com/ggaoshen/graph_wavenet.git. We import the `GraphWaveNet` model from our repo and load it to the Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1Re1G-ZlcQP",
        "outputId": "433f5ec2-4db9-4f23-de73-f1e98f2bca74"
      },
      "outputs": [],
      "source": [
        "# Import GraphWaveNet module\n",
        "!git clone https://github.com/ggaoshen/graph_wavenet.git\n",
        "%load graph_wavenet/src/graphwavenet.py\n",
        "import sys\n",
        "sys.path.append('graph_wavenet/src/')\n",
        "from graphwavenet import GraphWaveNet\n",
        "import util as util\n",
        "from util import masked_rmse, masked_mse, masked_mae, masked_mape, metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch Geometric Temporal\n",
        "PyTorch Geometric Temporal is a temporal graph neural network extension library for PyTorch Geometric. It builds on open-source deep-learning and graph processing libraries. It is the first open-source library for temporal deep learning on geometric structures and provides constant time difference graph neural networks on dynamic and static graphs.\n",
        "We install the PGT library to gain access to its strucures, functions and datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGgtAIg9lcQP",
        "outputId": "f4568942-dc52-4b6b-980e-923688a5ed1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-geometric-temporal\n",
            "  Downloading torch_geometric_temporal-0.54.0.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.1.0+cu121)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.0.6)\n",
            "Collecting pandas<=1.3.5 (from torch-geometric-temporal)\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch_sparse in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (0.6.18+pt21cu121)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.1.2+pt21cu121)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (1.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-geometric-temporal) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.3.5->torch-geometric-temporal) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-geometric-temporal) (2.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (4.66.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->torch-geometric-temporal) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-geometric-temporal) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric->torch-geometric-temporal) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->torch-geometric-temporal) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-geometric-temporal) (1.3.0)\n",
            "Building wheels for collected packages: torch-geometric-temporal\n",
            "  Building wheel for torch-geometric-temporal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric-temporal: filename=torch_geometric_temporal-0.54.0-py3-none-any.whl size=86722 sha256=4ffae596d28417b183e4fa11a37ab17ff4dffc39a91baff505458626fee2db25\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/9b/b6/e15256e053f0cb49b1084a67a709db909d418386a231f0722c\n",
            "Successfully built torch-geometric-temporal\n",
            "Installing collected packages: pandas, torch-geometric-temporal\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.16.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2023.7.0 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.3.5 torch-geometric-temporal-0.54.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -U torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hungarian Chickenpox Dataset\n",
        "PyTorch Geometric Temporal (PGT) provides the Chickenpox Cases in Hungary dataset, which shares the reported cases of chickenpox in Hungary by county on a weekly basis between 2005 and 2015, with (20) nodes representing counties and (61) undirected edges representing a “neighboring” relationship.  This is an example of a static graph with temporal signals.  The graph structure represents the regional geography, which is fixed, while the node features represent the number of cases of the disease, which varies over time. Further information on the dataset and its significance can be found at https://arxiv.org/abs/2102.08100.\n",
        "\n",
        "This colab will use our Graph WaveNet Framework to represent the Hungarian Chickenpox Dataset and learn to predict cases over a 10 week forecast. To do so, we download the dataset from PGT below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHipsw6jF91T",
        "outputId": "0259d7ec-04bd-476d-b24d-dda4234351bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n",
            "ChickenpoxDatasetLoader Data(x=[20, 8], edge_index=[2, 102], edge_attr=[102], y=[20])\n"
          ]
        }
      ],
      "source": [
        "import ssl\n",
        "\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
        "dataset = ChickenpoxDatasetLoader().get_dataset(lags=8) # consistent with chickenpox paper\n",
        "iterator = iter(dataset)\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))\n",
        "print(\"ChickenpoxDatasetLoader\", next(iterator))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import all the necessary PyTorch libraries for training the Graph WaveNet Framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# training\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache() # clear cuda cache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Temporal Signal Split\n",
        "This is an essential feature provided by PGT that helps to break the down in to training, validation, and testing datasets along the temporal dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_ratio = 0.8\n",
        "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=train_ratio)\n",
        "offset = int(dataset.snapshot_count * train_ratio) # starting index for test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "in_dim = dataset[0].num_node_features # 8 treat lagged inputs as node features\n",
        "out_dim = 1\n",
        "num_nodes = dataset[0].num_nodes # 20\n",
        "timesteps_to_predict = 10 # 10, 20, 40 week forecast horizon\n",
        "epochs = 200\n",
        "lrate = 0.0001\n",
        "wdecay = 0.001\n",
        "save_path = \"store/checkpoint\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Graph Wavenet - Extension\n",
        "To further improve our Graph WaveNet Framework, we introduced an extension framework to boost its performace while training on the Hungrarian Small Pox data set. Some key etension features include adding skip connections within the spatial temporal layers and introducing a learning rate decay scheduler.\n",
        "`util.extensions_enabled` flag controls the enablement of extensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph Wavenet - Extensions Enabled: True\n"
          ]
        }
      ],
      "source": [
        "# util.extensions_enabled controls the extensions that have been introduced to improve \n",
        "# the performance of Graph Wavenet. To turn off the extensions, set the below flag to False\n",
        "util.extensions_enabled = True\n",
        "print(\"Graph Wavenet - Extensions Enabled: {}\".format(util.extensions_enabled))\n",
        "if util.extensions_enabled:\n",
        "    epochs = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### GraphWaveNet\n",
        "This is our implementation of the framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = GraphWaveNet(\n",
        "    num_nodes=num_nodes,\n",
        "    in_channels=in_dim,\n",
        "    out_channels=out_dim,\n",
        "    out_timesteps=timesteps_to_predict,\n",
        ").to(device)\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Graph WaveNet Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:10<08:32, 10.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9674847308909748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|▍         | 2/50 [00:20<08:19, 10.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9505223805902572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 3/50 [00:31<08:13, 10.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9448683416516316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 4/50 [00:42<08:06, 10.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.94134298693843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 5/50 [00:52<07:59, 10.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9392352065116893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 6/50 [01:03<07:48, 10.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9385143716024553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 7/50 [01:13<07:34, 10.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9370799019660164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 8/50 [01:24<07:25, 10.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9367146764813763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 9/50 [01:35<07:13, 10.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9363697240583417\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 10/50 [01:45<07:02, 10.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9363710962190497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 11/50 [01:56<06:50, 10.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9360135251883327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 12/50 [02:06<06:39, 10.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9360795618648209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 13/50 [02:17<06:27, 10.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9361831195925067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 14/50 [02:27<06:17, 10.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9354952084718318\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 15/50 [02:38<06:07, 10.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358304221591935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 16/50 [02:48<05:58, 10.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358372203914858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 17/50 [02:59<05:47, 10.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9355800038067306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 18/50 [03:09<05:34, 10.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356565120152948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 19/50 [03:19<05:24, 10.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358742400685826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 20/50 [03:30<05:13, 10.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358321661311315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 21/50 [03:40<05:03, 10.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356529815440497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 22/50 [03:51<04:52, 10.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356146189088865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████▌     | 23/50 [04:01<04:42, 10.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9359998415428691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 24/50 [04:12<04:32, 10.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.935371215205367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 25/50 [04:22<04:21, 10.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.935047806449598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 26/50 [04:33<04:10, 10.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358797294837309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 27/50 [04:43<04:00, 10.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9353545269906157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 28/50 [04:54<03:50, 10.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.935878032750291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 29/50 [05:04<03:40, 10.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9360038714983114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 30/50 [05:15<03:29, 10.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356794605349622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 62%|██████▏   | 31/50 [05:25<03:19, 10.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.936208535749011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 32/50 [05:36<03:08, 10.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.936045776575622\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|██████▌   | 33/50 [05:46<02:58, 10.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356151348570498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 34/50 [05:56<02:47, 10.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358869732016833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 35/50 [06:07<02:37, 10.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356096574264329\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 72%|███████▏  | 36/50 [06:17<02:26, 10.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356663761478735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 37/50 [06:28<02:16, 10.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9357641171300557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 38/50 [06:39<02:05, 10.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9357863285692363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 39/50 [06:49<01:56, 10.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9359426470337118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 40/50 [07:00<01:45, 10.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358484828890097\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 41/50 [07:10<01:34, 10.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358116518796944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%|████████▍ | 42/50 [07:21<01:24, 10.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356783381549687\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▌ | 43/50 [07:31<01:13, 10.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9357474224005894\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 44/50 [07:42<01:03, 10.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9358203468844295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 45/50 [07:52<00:52, 10.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9359791791566261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 46/50 [08:03<00:42, 10.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9355495688937059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 47/50 [08:13<00:31, 10.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356997588058797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 96%|█████████▌| 48/50 [08:24<00:21, 10.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356149292391974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 49/50 [08:34<00:10, 10.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9356020801041911\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [08:45<00:00, 10.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training loss: 0.9357193153306115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"start training...\", flush=True)\n",
        "his_loss = []\n",
        "val_time = []\n",
        "train_time = []\n",
        "best_epoch = 0\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lrate, weight_decay=wdecay)\n",
        "\n",
        "scheduler = None\n",
        "clip = None\n",
        "\n",
        "# As part of extensions, we enable learning rate decay and gradient clipping\n",
        "if util.extensions_enabled:\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.99)\n",
        "    clip = 5\n",
        "\n",
        "model.train()\n",
        "\n",
        "def prepare_n_period_y(dataset):\n",
        "\n",
        "    res = []\n",
        "    for data in dataset:\n",
        "        res.append(data.y)\n",
        "    res = torch.stack(res, dim=0)\n",
        "\n",
        "    return res\n",
        "\n",
        "y_all = prepare_n_period_y(dataset)\n",
        "training_curve_dict = {\"epoch_train_loss\": []}\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss = []\n",
        "    t1 = time.time()\n",
        "\n",
        "    for i, snapshot in enumerate(train_dataset):\n",
        "        x_train = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "        if timesteps_to_predict == 1:\n",
        "            y_train = snapshot.y.to(device)\n",
        "        else:\n",
        "            y_train = y_all[i : i + timesteps_to_predict,:].to(device)\n",
        "\n",
        "        pred = model(x_train, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "        loss = masked_mse(pred, y_train, 0.0) # mean squared error for loss\n",
        "        loss.backward()\n",
        "\n",
        "        if util.extensions_enabled:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if util.extensions_enabled:\n",
        "            scheduler.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "    mtrainloss = np.mean(train_loss)\n",
        "    training_curve_dict['epoch_train_loss'].append(mtrainloss)\n",
        "    print(f\"training loss: {mtrainloss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Graph WaveNet Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test MSE Loss: 0.9548\n"
          ]
        }
      ],
      "source": [
        "# eval\n",
        "model.eval()\n",
        "loss = 0\n",
        "for i, snapshot in enumerate(test_dataset):\n",
        "    if i + timesteps_to_predict > test_dataset.snapshot_count:\n",
        "        break\n",
        "\n",
        "    x_test = snapshot.x.reshape(-1, num_nodes, in_dim).to(device)\n",
        "\n",
        "    if timesteps_to_predict == 1:\n",
        "        y_test = snapshot.y.to(device)\n",
        "    else:\n",
        "        y_test = y_all[offset+i : offset+i + timesteps_to_predict,:].to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model(x_test, snapshot.edge_index, snapshot.edge_attr).squeeze()\n",
        "    loss += masked_mse(pred, y_test, 0.0) # mean squared error as loss\n",
        "\n",
        "loss = loss / (i+1)\n",
        "loss = loss.item()\n",
        "print(\"Test MSE Loss: {:.4f}\".format(loss))\n",
        "\n",
        "\n",
        "# store training loss\n",
        "pd.DataFrame(training_curve_dict).to_csv(\"training_curve.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "rW_Gc1oQ8rNC",
        "outputId": "c5d9ba7e-e8ae-44ba-b030-478ad0ecf948"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('training_curve.csv')\n",
        "training_curve_dict[\"epoch_train_loss\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
